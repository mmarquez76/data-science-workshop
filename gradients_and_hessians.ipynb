{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Data Science <br>PantherHacks 2020\n",
    "\n",
    "To begin your data science journey, please answer the following basic foundational math questions. Copy this notebook and submit your answers under each problem, inserting cells as needed. You may use a combination of [python](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Running%20Code.html), [markdown](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html), and [LaTex](http://data-blog.udacity.com/posts/2016/10/latex-primer/) to formulate your responses. \n",
    "\n",
    "## **This assignment is aimed at absolute beginners to data science.**\n",
    "\n",
    "### **There is no prior knowledge needed for this assignment**\n",
    "except for a working understanding of [multi-variable calculus](https://www.khanacademy.org/math/multivariable-calculus), [linear algebra](https://www.khanacademy.org/math/linear-algebra), and [statistics](https://www.khanacademy.org/math/statistics-probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workshop Part 1: **[Gradients](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/the-gradient) and [Hessians](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/quadratic-approximations/a/the-hessian)**\n",
    "\n",
    "A matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is considered *symmetric* if $\\mathbf{A}^{T}=\\mathbf{A}$, that is if $\\mathbf{A}_{ij} = \\mathbf{A}_{ji}$ for every $i,j$. The **gradient**, $\\nabla f(x)$, of a function, $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$, is defined as the *n*-vector of partial derivatives\n",
    "\n",
    "$$\\nabla f(x) = \\begin{bmatrix} \\frac{\\partial}{\\partial x_1}f(x) \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial x_n}f(x) \\end{bmatrix} \\text{ where } \\mathbf{x}=\\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix}.$$\n",
    "\n",
    "Similarly, the Hessian, $\\nabla^2 f(x)$ of a function, $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$, is the $n \\times n$ symmetric matrix of second-order partial derivatives, \n",
    "\n",
    "\n",
    "$$\\nabla^2 f(x) = \\begin{bmatrix} \\frac{\\partial^2}{\\partial x^2_1}f(x) & \\frac{\\partial^2}{\\partial x_1 \\partial x_2}f(x) & \\dots & \\frac{\\partial^2}{\\partial x_1 \\partial x_n}f(x) \\\\ \\frac{\\partial^2}{\\partial x_2 \\partial x_1}f(x) & \\frac{\\partial^2}{\\partial x^2_2}f(x) & \\dots & \\frac{\\partial^2}{\\partial x_2 \\partial x_n}f(x) \\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial^2}{\\partial x_n \\partial x_1}f(x) & \\frac{\\partial^2}{\\partial x_n \\partial x_2}f(x) & \\dots & \\frac{\\partial}{\\partial x^2_n}f(x) \\end{bmatrix}.$$\n",
    "\n",
    "a) Let $f(x)= \\frac{1}{2}\\mathbf{x}^T\\mathbf{A}\\mathbf{x} + \\mathbf{b}^T\\mathbf{x}$ where $\\mathbf{A}$ is a symmetric matrix and $\\mathbf{b} \\in \\mathbb{R}^n$ is a vector. What is $\\nabla f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Let $f(x)=g(h(x))$, where $g: \\mathbb{R} \\rightarrow \\mathbb{R}$ is differentiable and $h: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is differentiable. What is $\\nabla f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Let $f(x)= \\frac{1}{2}\\mathbf{x}^T\\mathbf{A}\\mathbf{x} + \\mathbf{b}^T\\mathbf{x}$ where $\\mathbf{A}$ is a symmetric matrix and $\\mathbf{b} \\in \\mathbb{R}^n$ is a vector. What is $\\nabla^2 f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Let $f(x)=g(a^Tx)$, where $g: \\mathbb{R} \\rightarrow \\mathbb{R}$ is continuously differentiable and $a \\in \\mathbb{R}^n$ is a vector. What are $\\nabla f(x)$ and $\\nabla^2 f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2. **[Eigen Vectors, eigenvalues, and the spectral theorem](https://www.khanacademy.org/math/linear-algebra/alternate-bases#eigen-everything)**  \n",
    "\n",
    "The eigen values of an nxn matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ are the roots of the characteristic polynomial $p_A(\\lambda)= \\text{det}(\\lambda \\mathbf{I} - \\mathbf{A})$, which may be in general complex. They are also defined as the values $\\lambda \\in \\mathbb{C}$ for which there exists a vector $\\mathbf{x} \\in \\mathbb{C}^n$ to the n  such that $\\mathbf{A}\\mathbf{x} = \\lambda \\mathbf{x}$. We call such a pair $(\\mathbf{x}, \\lambda)$, the *eigenvector*, *eigenvalue* pair. Here we use the notation $\\text{diag}(\\lambda_1,\\dots,\\lambda_n)$ to denote the diagonal matrix with diagonal entries $\\lambda_1, \\dots, \\lambda_n$ that is,\n",
    "\n",
    "$$\\text{diag}(\\lambda_1,\\dots,\\lambda_n) = \\begin{bmatrix} \\lambda_1 & 0 & 0 & \\dots & 0 \\\\ 0 & \\lambda_2 & 0 & \\dots & 0 \\\\ 0 & 0 & \\lambda_3 & \\dots & 0 \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & 0 & \\dots & \\lambda_n \\end{bmatrix}.$$\n",
    "\n",
    "a) Suppose that the matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is diagonalizable, that is, $\\mathbf{A} = \\mathbf{T} \\mathbf{\\Lambda} \\mathbf{T}^{-1}$ for an invertible matrix $\\mathbf{T} \\in \\mathbb{R}^{n \\times n}$, where $\\mathbf{\\Lambda} = \\text{diag}(\\lambda_1, \\dots, \\lambda_n)$ is diagonal. Use the notation $t^{(i)}$ for the columns of $\\mathbf{T}$, so that $\\mathbf{T} = \\begin{bmatrix} t^{(1)} & \\dots & t^{(n)}\\end{bmatrix}$, where $t^{(i)} \\in \\mathbb{R}^n$. Show that $\\mathbf{A}t^{(i)} = \\lambda_i t^{(i)}$ so that the eigenvalue/eigenvector pairs of $\\mathbf{A}$ are $(t^{(i)}, \\lambda_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $\\mathbf{U} \\in \\mathbb{R}^{n \\times n}$ is *orthogonal* if $\\mathbf{U}^T\\mathbf{U}=\\mathbf{I}$. The spectral theorem states that if $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is symmetric, that is $\\mathbf{A} = \\mathbf{A}^T$, then $\\mathbf{A}$ is *diagonalizable by a real orthogonal matrix*. In other words, there are a diagonal matrix $\\mathbf{\\Lambda} \\in \\mathbb{R}^{n \\times n}$ and orthogonal matrix $\\mathbf{U} \\in \\mathbb{R}^{n \\times n}$ such that $\\mathbf{U}^T\\mathbf{A}\\mathbf{U} = \\mathbf{\\Lambda}$, or equivalently,\n",
    "$$\\mathbf{A}=\\mathbf{U}\\mathbf{\\Lambda} \\mathbf{U}^T.$$\n",
    "\n",
    "Let $\\lambda_i = \\lambda_i(\\mathbf{A})$ denote the $i$th eigenvalue of $\\mathbf{A}$.\n",
    "\n",
    "b) Let $\\mathbf{A}$ be symmetric. Show that if $\\mathbf{U} = \\begin{bmatrix} u^{(1)} & \\dots & u^{(n)} \\end{bmatrix}$ is orthogonal, where $u^{(i)} \\in \\mathbb{R}^n$ and $\\mathbf{A}=\\mathbf{U}\\mathbf{\\Lambda} \\mathbf{U}^T$, then $u^{(i)}$ is an eigenvector of $\\mathbf{A}$ and $\\mathbf{A}u^{(i)} = \\lambda_i u^{(i)}$, where $\\mathbf{\\Lambda} = \\text{diag}(\\lambda_1, \\dots, \\lambda_n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Show that if $\\mathbf{A}$ is positive semi-definite, then $\\lambda_i(\\mathbf{A}) \\geq 0$ for each $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3. **[Positive definite matrices](https://cedar.buffalo.edu/~srihari/CSE574/Chap1/LinearAlgebra.pdf)**  \n",
    "\n",
    "A matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is *positive semi-definite* (PSD), denoted $\\mathbf{A} \\succeq 0$, if $\\mathbf{A} = \\mathbf{A}^T$ and $\\mathbf{x}^T\\mathbf{A}\\mathbf{x} \\geq 0$ for all $\\mathbf{x} \\in \\mathbb{R}^n$. A matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is *positive definite*, denoted $\\mathbf{A} \\succ 0$, if $\\mathbf{A} = \\mathbf{A}^T$ and $\\mathbf{x}^T\\mathbf{A}\\mathbf{x} \\gt 0$ for all $\\mathbf{x} \\neq 0$, that is, all non-zero vectors $\\mathbf{x}$. In simple terms, a matrix $\\mathbf{A}$ whose eigenvalues are all positive is called *positive definite*. A matrix $\\mathbf{A}$ whose eigenvalues are all positive or zero is called positive semi-definite. If the eigenvalues of a matrix $\\mathbf{A}$ are negative, then the matrix is said to be negative definite.\n",
    "\n",
    "a)Recall the identity matrix, $\\mathbf{I}_n$, is a matrix of size $n \\times n$ with ones along the diagonal. For example, $\\mathbf{I}_3$ is\n",
    "\n",
    "$$\\mathbf{I}_3 = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}$$\n",
    "\n",
    "Show that the identity matrix $\\mathbf{I}_n$ is positive definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Let $\\mathbf{z} \\in \\mathbb{R}^n$ be an $n$-vector. Show that $\\mathbf{A} = \\mathbf{z}\\mathbf{z}^T$ is positive semi-definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Let $\\mathbf{z} \\in \\mathbb{R}^n$ be a *non-zero* $n$-vector. Let $\\mathbf{A} = \\mathbf{z}\\mathbf{z}^T$. What is the [nullspace](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/null-space-2-calculating-the-null-space-of-a-matrix) of $\\mathbf{A}$? What is the [rank](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/dimension-of-the-column-space-or-rank) of $\\mathbf{A}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Let $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ be positive semi-definite and $\\mathbf{B} \\in \\mathbb{R}^{m \\times n}$ be arbitrary, where $m,n \\in \\mathbb{N}$. Is $\\mathbf{B}\\mathbf{A}\\mathbf{B}^T$ PSD? If so, prove it. If not, give a counter example with explicit $\\mathbf{A},\\mathbf{B}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4. **[Probability, Statistics, and Conditional Probability](https://www.cs.cmu.edu/~aarti/Class/10701/recitation/prob_review.pdf)**\n",
    "\n",
    "An aircraft emergency locator transmitter (ELT) is a device designed to transmit a signal in the case of a crash. The ACME Manufacturing Company makes 70% of the ELTs, the B. BUNNY Company makes 25% of them, and the W. E. COYOTE Company makes the other 5%. The ELTs made by ACME have a 3.5% rate of defects, the B. BUNNY ELTs have a 5% rate of defects, and the W. E. COYOTE ELTs have a 8% rate of defects (which helps to explain why W. E. COYOTE has the lowest market share).\n",
    "\n",
    "a) If a locator is randomly selected from the general population of all locators, find the probability that it was made by the ACME Manufacturing Company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) If a randomly selected locator is then tested and is found to be defective, find the probability that it was made by the ACME Manufacturing Company."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}